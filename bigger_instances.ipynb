{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "imported_module = importlib.import_module(\"sql_commands\")\n",
    "importlib.reload(imported_module)\n",
    "import sql_commands\n",
    "from sql_commands import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "make db with sizes 0.2, 0.4, and 0.6 and run same time comparison\n",
    "for every query(1,2,3,4):\n",
    "    for every database(100mb,200mb,300mb):\n",
    "        for every null rate(1%,5%):\n",
    "            run query and get time\n",
    "            run query+ and get time\n",
    "            get range\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_sizes = [\"100MB\", \"200MB\", \"200MB\"]\n",
    "db_names = ['tpch', 'tpch_200mb', 'tpch_300mb']\n",
    "null_rates = [0.01, 0.05]\n",
    "mydb, mycursor = sql_commands.connect_to_db(\"tpch_2pct\")\n",
    "if not os.path.exists(\"performance_results\"):\n",
    "    # If it doesn't exist, create it\n",
    "    os.makedirs(\"performance_results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tpch\n",
      "0.01 0.9968902402189721\n",
      "0.05 1.2067979388031287\n",
      "(0.9968902402189721, 1.2067979388031287)\n",
      "tpch_200mb\n",
      "0.01 0.962108103451462\n",
      "0.05 0.9257700283358385\n",
      "(0.9257700283358385, 0.962108103451462)\n",
      "tpch_300mb\n",
      "0.01 1.2633571389659655\n",
      "0.05 1.0881184233346486\n",
      "(1.0881184233346486, 1.2633571389659655)\n"
     ]
    }
   ],
   "source": [
    "q1_nations = ['UNITED KINGDOM', 'ARGENTINA', 'PERU', 'FRANCE', 'BRAZIL']\n",
    "q1_results = []\n",
    "for db_name in db_names:\n",
    "    print(db_name)\n",
    "    intermediate_results = []\n",
    "    for null_rate in null_rates:\n",
    "        null_rate_pct = int(null_rate * 100)\n",
    "        actual_db_name = f\"{db_name}_{null_rate_pct}pct\"\n",
    "        #print(\"Using\", actual_db_name)\n",
    "        mydb, mycursor = sql_commands.connect_to_db(actual_db_name)\n",
    "        ratios = []\n",
    "        for i in range(5):\n",
    "            result, q1_time, nation = run_query1(mycursor, q1_nations[i%len(q1_nations)], simple=False)\n",
    "            result, q1_mod_time = run_query1_modified(mycursor, nation)\n",
    "            ratio = q1_mod_time / q1_time\n",
    "            ratios.append(ratio)\n",
    "        avg = np.mean(ratios)\n",
    "        # print(null_rate, avg)\n",
    "        intermediate_results.append(avg)\n",
    "    min = np.min(intermediate_results)\n",
    "    max = np.max(intermediate_results)\n",
    "    # print((min,max))\n",
    "    q1_results.append((min,max))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.9968902402189721, 1.2067979388031287),\n",
       " (0.9257700283358385, 0.962108103451462),\n",
       " (1.0881184233346486, 1.2633571389659655)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_nations_raw = sql_commands.run_query(mycursor, \"SELECT N_NAME FROM NATION\")\n",
    "all_nations = []\n",
    "for nation in all_nations_raw:\n",
    "    n = nation[0]\n",
    "    if n is not None:\n",
    "        all_nations.append(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tpch\n",
      "(0.161552960996379, 0.17062713434096655)\n",
      "tpch_200mb\n",
      "(0.0873216050566439, 0.13543533274128716)\n",
      "tpch_300mb\n",
      "(0.07529283921818318, 0.11197839286084457)\n"
     ]
    }
   ],
   "source": [
    "q2_results = []\n",
    "for db_name in db_names:\n",
    "    print(db_name)\n",
    "    intermediate_results = []\n",
    "    for null_rate in null_rates:\n",
    "        null_rate_pct = int(null_rate * 100)\n",
    "        actual_db_name = f\"{db_name}_{null_rate_pct}pct\"\n",
    "        #print(\"Using\", actual_db_name)\n",
    "        mydb, mycursor = sql_commands.connect_to_db(actual_db_name)\n",
    "        ratios = []\n",
    "        for i in range(5):\n",
    "            nations = tuple(random.sample(all_nations, 7))\n",
    "            result, q2_time, countries = run_query2(mycursor, nations, simple=False)\n",
    "            result, q2_mod_time = run_query2_modified(mycursor, countries)\n",
    "            ratio = q2_mod_time / q2_time\n",
    "            ratios.append(ratio)\n",
    "        avg = np.mean(ratios)\n",
    "        # print(null_rate, avg)\n",
    "        intermediate_results.append(avg)\n",
    "    min = np.min(intermediate_results)\n",
    "    max = np.max(intermediate_results)\n",
    "    print((min,max))\n",
    "    q2_results.append((min,max))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tpch\n",
      "(0.9296502860647173, 0.9644546278764198)\n",
      "tpch_200mb\n",
      "(1.1828288357467793, 1.281917846961201)\n",
      "tpch_300mb\n",
      "(0.8998112577971751, 0.9837995194566254)\n"
     ]
    }
   ],
   "source": [
    "q3_results = []\n",
    "for db_name in db_names:\n",
    "    print(db_name)\n",
    "    intermediate_results = []\n",
    "    for null_rate in null_rates:\n",
    "        null_rate_pct = int(null_rate * 100)\n",
    "        actual_db_name = f\"{db_name}_{null_rate_pct}pct\"\n",
    "        #print(\"Using\", actual_db_name)\n",
    "        mydb, mycursor = sql_commands.connect_to_db(actual_db_name)\n",
    "        ratios = []\n",
    "        for i in range(5):\n",
    "            result, q3_time, supp_key = run_query3(mycursor, simple=False)\n",
    "            result, q3_mod_time = run_query3_modified(mycursor, supp_key)\n",
    "            ratio = q3_mod_time / q3_time\n",
    "            ratios.append(ratio)\n",
    "        avg = np.mean(ratios)\n",
    "        # print(null_rate, avg)\n",
    "        intermediate_results.append(avg)\n",
    "    min = np.min(intermediate_results)\n",
    "    max = np.max(intermediate_results)\n",
    "    print((min,max))\n",
    "    q3_results.append((min,max))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tpch\n",
      "(1.6582126640348276, 278.5049499552743)\n",
      "tpch_200mb\n",
      "(17.123516010385497, 461.3505701197999)\n",
      "tpch_300mb\n",
      "(29.423968607700463, 1653.914664064291)\n"
     ]
    }
   ],
   "source": [
    "q4_results = []\n",
    "for db_name in db_names:\n",
    "    print(db_name)\n",
    "    intermediate_results = []\n",
    "    for null_rate in null_rates:\n",
    "        null_rate_pct = int(null_rate * 100)\n",
    "        actual_db_name = f\"{db_name}_{null_rate_pct}pct\"\n",
    "        #print(\"Using\", actual_db_name)\n",
    "        mydb, mycursor = sql_commands.connect_to_db(actual_db_name)\n",
    "        ratios = []\n",
    "        for i in range(1):\n",
    "            result, q4_time, nation, color = run_query4(mycursor, all_nations, simple=False)\n",
    "            result, q4_mod_time = run_query4_modified(mycursor, nation, color)\n",
    "            ratio = q4_mod_time / q4_time\n",
    "            # print(\"times\", q4_mod_time, q4_time)\n",
    "            ratios.append(ratio)\n",
    "        avg = np.mean(ratios)\n",
    "        # print(null_rate, avg)\n",
    "        intermediate_results.append(avg)\n",
    "    min = np.min(intermediate_results)\n",
    "    max = np.max(intermediate_results)\n",
    "    print((min,max))\n",
    "    q4_results.append((min,max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV data has been written to bigger_instances_results.csv\n"
     ]
    }
   ],
   "source": [
    "rows = zip(q1_results, q2_results, q3_results, q4_results)\n",
    "header_row = ['100MB', '200MB', '300MB']\n",
    "# Open the file in write mode and use csv.writer to write the rows\n",
    "path = \"bigger_instances_results.csv\"\n",
    "with open(path, \"w\", newline=\"\") as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    writer.writerow(header_row)\n",
    "    writer.writerows(rows)\n",
    "\n",
    "print(\"CSV data has been written to\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------+--------------------------------------------+------------------------------------------+-----------------------------------------+\n",
      "| Query                                    | 100MB                                      | 200MB                                    | 300MB                                   |\n",
      "+==========================================+============================================+==========================================+=========================================+\n",
      "| Q1                                       | Q2                                         | Q3                                       | Q4                                      |\n",
      "+------------------------------------------+--------------------------------------------+------------------------------------------+-----------------------------------------+\n",
      "| (0.9968902402189721, 1.2067979388031287) | (0.161552960996379, 0.17062713434096655)   | (0.9296502860647173, 0.9644546278764198) | (1.6582126640348276, 278.5049499552743) |\n",
      "+------------------------------------------+--------------------------------------------+------------------------------------------+-----------------------------------------+\n",
      "| (0.9257700283358385, 0.962108103451462)  | (0.0873216050566439, 0.13543533274128716)  | (1.1828288357467793, 1.281917846961201)  | (17.123516010385497, 461.3505701197999) |\n",
      "+------------------------------------------+--------------------------------------------+------------------------------------------+-----------------------------------------+\n",
      "| (1.0881184233346486, 1.2633571389659655) | (0.07529283921818318, 0.11197839286084457) | (0.8998112577971751, 0.9837995194566254) | (29.423968607700463, 1653.914664064291) |\n",
      "+------------------------------------------+--------------------------------------------+------------------------------------------+-----------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "# Specify the file path from which you want to read the CSV data\n",
    "file_path = \"bigger_instances_results.csv\"\n",
    "\n",
    "# Read data from the CSV file\n",
    "with open(file_path, newline='') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    # Assuming the first row contains the header\n",
    "    header = next(reader)\n",
    "    # Read the remaining rows as data\n",
    "    data = [row for row in reader]\n",
    "\n",
    "# Print the data as a nice table\n",
    "print(tabulate(data, headers=header, tablefmt='grid'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
